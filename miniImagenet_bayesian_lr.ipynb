{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multi-class Bayesian Logistic Regression with PyMC3 ~ Softmax Regression\n",
    "* From the \"Bayesian Analysis with Python\" book repository\n",
    "* written by Osvaldo Martin \n",
    "- credit: https://github.com/aloctavodia/BAP/blob/master/code_3_11/Chp4/04_Generalizing_linear_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano.tensor as tt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.special import expit as logistic\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import arviz as az\n",
    "# az.style.use('arviz-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore one classification task of MiniImagenet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f#1</th>\n",
       "      <th>f#2</th>\n",
       "      <th>f#3</th>\n",
       "      <th>f#4</th>\n",
       "      <th>f#5</th>\n",
       "      <th>f#6</th>\n",
       "      <th>f#7</th>\n",
       "      <th>f#8</th>\n",
       "      <th>f#9</th>\n",
       "      <th>f#10</th>\n",
       "      <th>...</th>\n",
       "      <th>f#632</th>\n",
       "      <th>f#633</th>\n",
       "      <th>f#634</th>\n",
       "      <th>f#635</th>\n",
       "      <th>f#636</th>\n",
       "      <th>f#637</th>\n",
       "      <th>f#638</th>\n",
       "      <th>f#639</th>\n",
       "      <th>f#640</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.127699</td>\n",
       "      <td>0.122649</td>\n",
       "      <td>0.267785</td>\n",
       "      <td>0.411345</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>0.244845</td>\n",
       "      <td>0.177270</td>\n",
       "      <td>0.062307</td>\n",
       "      <td>0.087690</td>\n",
       "      <td>0.396385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066463</td>\n",
       "      <td>0.064247</td>\n",
       "      <td>0.146898</td>\n",
       "      <td>0.196495</td>\n",
       "      <td>0.242408</td>\n",
       "      <td>0.308071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070882</td>\n",
       "      <td>0.216365</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.240852</td>\n",
       "      <td>0.079247</td>\n",
       "      <td>0.180397</td>\n",
       "      <td>0.118170</td>\n",
       "      <td>0.094469</td>\n",
       "      <td>0.158827</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043164</td>\n",
       "      <td>0.275873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133642</td>\n",
       "      <td>0.073552</td>\n",
       "      <td>0.307174</td>\n",
       "      <td>0.156293</td>\n",
       "      <td>0.103464</td>\n",
       "      <td>0.087708</td>\n",
       "      <td>0.111950</td>\n",
       "      <td>0.199864</td>\n",
       "      <td>0.140848</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.099519</td>\n",
       "      <td>0.015915</td>\n",
       "      <td>0.070350</td>\n",
       "      <td>0.069683</td>\n",
       "      <td>0.076358</td>\n",
       "      <td>0.138744</td>\n",
       "      <td>0.078485</td>\n",
       "      <td>0.088263</td>\n",
       "      <td>0.027818</td>\n",
       "      <td>0.179175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126843</td>\n",
       "      <td>0.095335</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.050464</td>\n",
       "      <td>0.197668</td>\n",
       "      <td>0.064714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021860</td>\n",
       "      <td>0.073881</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050765</td>\n",
       "      <td>0.244135</td>\n",
       "      <td>0.213204</td>\n",
       "      <td>0.040929</td>\n",
       "      <td>0.114006</td>\n",
       "      <td>0.106969</td>\n",
       "      <td>0.082816</td>\n",
       "      <td>0.063005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>0.027693</td>\n",
       "      <td>0.113846</td>\n",
       "      <td>0.105648</td>\n",
       "      <td>0.243614</td>\n",
       "      <td>0.114662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125564</td>\n",
       "      <td>0.191768</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037901</td>\n",
       "      <td>0.106554</td>\n",
       "      <td>0.150849</td>\n",
       "      <td>0.056228</td>\n",
       "      <td>0.155305</td>\n",
       "      <td>0.082078</td>\n",
       "      <td>0.036916</td>\n",
       "      <td>0.018294</td>\n",
       "      <td>0.070951</td>\n",
       "      <td>0.354087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268142</td>\n",
       "      <td>0.055179</td>\n",
       "      <td>0.263597</td>\n",
       "      <td>0.268285</td>\n",
       "      <td>0.235611</td>\n",
       "      <td>0.080541</td>\n",
       "      <td>0.273199</td>\n",
       "      <td>0.040098</td>\n",
       "      <td>0.027004</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 641 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f#1       f#2       f#3       f#4       f#5       f#6       f#7  \\\n",
       "0  0.127699  0.122649  0.267785  0.411345  0.004119  0.244845  0.177270   \n",
       "1  0.240852  0.079247  0.180397  0.118170  0.094469  0.158827  0.016343   \n",
       "2  0.099519  0.015915  0.070350  0.069683  0.076358  0.138744  0.078485   \n",
       "3  0.050765  0.244135  0.213204  0.040929  0.114006  0.106969  0.082816   \n",
       "4  0.037901  0.106554  0.150849  0.056228  0.155305  0.082078  0.036916   \n",
       "\n",
       "        f#8       f#9      f#10  ...     f#632     f#633     f#634     f#635  \\\n",
       "0  0.062307  0.087690  0.396385  ...  0.066463  0.064247  0.146898  0.196495   \n",
       "1  0.000000  0.043164  0.275873  ...  0.133642  0.073552  0.307174  0.156293   \n",
       "2  0.088263  0.027818  0.179175  ...  0.126843  0.095335  0.068477  0.050464   \n",
       "3  0.063005  0.000000  0.188420  ...  0.014825  0.027693  0.113846  0.105648   \n",
       "4  0.018294  0.070951  0.354087  ...  0.268142  0.055179  0.263597  0.268285   \n",
       "\n",
       "      f#636     f#637     f#638     f#639     f#640  label  \n",
       "0  0.242408  0.308071  0.000000  0.070882  0.216365    0.0  \n",
       "1  0.103464  0.087708  0.111950  0.199864  0.140848    1.0  \n",
       "2  0.197668  0.064714  0.000000  0.021860  0.073881    2.0  \n",
       "3  0.243614  0.114662  0.000000  0.125564  0.191768    3.0  \n",
       "4  0.235611  0.080541  0.273199  0.040098  0.027004    4.0  \n",
       "\n",
       "[5 rows x 641 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the support set\n",
    "miniImagenet_train = pd.read_csv('./data/miniImagenet/support_run_0.csv')\n",
    "miniImagenet_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(miniImagenet_train.label.unique())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for Bayesian Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points: 5\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.Categorical(miniImagenet_train['label']).codes       # {0,1,2,3,4} \n",
    "x_train_cols = miniImagenet_train.columns.difference(['label'])\n",
    "\n",
    "x_train = miniImagenet_train[x_train_cols].values                # shape: (number of datapoints, number of features)\n",
    "num_data_points, num_feats = x_train.shape\n",
    "print(f\"number of data points: {num_data_points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the features values (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std_scaler = StandardScaler()\n",
    "# std_scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(x_train.mean(axis=0) == std_scaler.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(x_train.std(axis=0) == std_scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sara/anaconda3/envs/bayes/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/home/sara/anaconda3/envs/bayes/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "/home/sara/anaconda3/envs/bayes/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [β, α]\n",
      "  0%|                                        | 0/1000 [00:00<?, ?it/s]/home/sara/anaconda3/envs/bayes/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "100%|█████████████████████████████| 1000/1000 [00:12<00:00, 82.18it/s]\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time for 5 data points and 640 features is: 18.1744 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "num_samples = 500\n",
    "num_chains = 1\n",
    "\n",
    "\n",
    "with pm.Model() as model_s:\n",
    "    α = pm.Normal('α', mu=0, sd=5, shape=num_classes)             # bias term\n",
    "    β = pm.Normal('β', mu=0, sd=5, shape=(num_feats,num_classes))         # feature weight\n",
    "    μ = pm.Deterministic('μ', α + pm.math.dot(x_train, β))  # linear combination of the features\n",
    "    θ = tt.nnet.softmax(μ)                              # softmax prediction (150, 3)\n",
    "    yl = pm.Categorical('yl', p=θ, observed=y_train)\n",
    "    # idata_s = pm.sample(num_samples, target_accept=0.9, return_inferencedata=True)\n",
    "    idata_s = pm.sample(num_samples, chains=num_chains, target_accept=0.9, return_inferencedata=True)\n",
    "    \n",
    "end = time.time()\n",
    "print(f\"elapsed time for {num_data_points} data points and {num_feats} features is: {(end - start):.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['α', 'β', 'μ'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idata_s[0]['μ'].shape\n",
    "idata_s[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idata_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idata_s.nchains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['α', 'β', 'μ']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idata_s.varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idata_s.chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONT REMOVE\n",
    "# i = 0\n",
    "# for pmc_iter in idata_s.points(): # 8000 iterations (i.e. number of points = 4 chains x 2000 iterations)\n",
    "#     logits_vals = np.vstack(\n",
    "    # print(pmc_iter.keys())        # dict_keys(['α', 'β', 'μ'])\n",
    "    # print(pmc_iter['μ'].shape)    # (150,3) for each iteration we have (150,3) μ : logit values of 150 datapoints: (150, 3) (to be passed to softmax predcition next)\n",
    "    # print(pmc_iter['β'].shape)    # (4,3)   for each iteration we have   (4,3) β\n",
    "    # print(pmc_iter['α'].shape)    # (3,)    for each iteration we have    (3,) α\n",
    "\n",
    "#     i+=1\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 5, 5)\n",
      "(500, 5)\n",
      "(500, 640, 5)\n"
     ]
    }
   ],
   "source": [
    "# DONT REMOVE\n",
    "print(idata_s.get_values('μ').shape)   # shape (8000, 150, 3) ---> (num_iters, num_data_points, num_classes)\n",
    "print(idata_s.get_values('α').shape)   # shape (8000, 3)      ---> (num_iters, num_classes)\n",
    "print(idata_s.get_values('β').shape)   # shape (8000, 4, 3)   ---> (num_iters, num_feats, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00\n"
     ]
    }
   ],
   "source": [
    "# get logits by averaging over the num_iters (here 8000)\n",
    "# shape of μ is (num_iters, num_data_points, num_classes)\n",
    "data_pred = idata_s.get_values('μ').mean(axis=0)   # logits for training data: shape (150, 3)\n",
    "\n",
    "# softmax prediction for the 150 datapoint in the training dataset\n",
    "y_pred = [np.exp(point)/np.sum(np.exp(point), axis=0) for point in data_pred]   # len(y_pred) = num_data_points\n",
    "\n",
    "# accuracy of the training data = 98%\n",
    "print(f'{np.sum(y_train == np.argmax(y_pred, axis=1)) / len(y_train):.2f}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_softmax_prediction(x_test, y_test, α, β, estimate_type='mean'):   \n",
    "    '''\n",
    "    x_test: held-out test data.     shape = (num_data_points, num_feats)\n",
    "    y_test: held-out true labels.   shape = (num_data_points,)\n",
    "    α: bias term.                   shape = (num_iters, num_classes)\n",
    "    β: features weights.            shape = (num_iters, num_feats, num_classes)\n",
    "    estimate_type: available options = ['mean', 'median', 'mode'], default value is: 'mean'\n",
    "    '''\n",
    "    if estimate_type == \"mean\":\n",
    "        y_pred = α.mean(axis=0) + np.dot(x_test, β.mean(axis=0))    # first term shape: ?? , second term shape: (num_points, num_classes)\n",
    "    \n",
    "    elif estimate_type == \"median\":\n",
    "        y_pred = np.median(α, axis=0) + np.dot(x_test, np.median(β, axis=0))\n",
    "        \n",
    "    elif estimate_type == \"mode\":\n",
    "        α_mode = stats.mode(α, axis=0)[0].squeeze()\n",
    "        β_mode = stats.mode(β, axis=0)[0].squeeze()\n",
    "        y_pred = α_mode + np.dot(x_test, β_mode)\n",
    "    proba = np.exp(y_pred).T/np.sum(np.exp(y_pred), axis=1)\n",
    "    p_class = np.argmax(proba, axis=0)\n",
    "    \n",
    "    accuracy = np.sum(y_test == np.argmax(y_pred, axis=1)) / len(y_test)\n",
    "    return proba, p_class, accuracy * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict support set (i.e. training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian parameters from the drawn samples\n",
    "α = idata_s.get_values('α')\n",
    "β = idata_s.get_values('β')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint: 'mode' estimate type takes more time than 'mean' and 'median'\n",
    "y_proba, y_pred, accuracy = get_softmax_prediction(x_train, y_train, α, β, estimate_type='median')\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict query set (held-out data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 641)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miniImagenet_test = pd.read_csv('./data/miniImagenet/query_run_0.csv')\n",
    "miniImagenet_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.Categorical(miniImagenet_test['label']).codes       # {0,1,2,3,4} \n",
    "x_test_cols = miniImagenet_test.columns.difference(['label'])\n",
    "x_test = miniImagenet_test[x_test_cols].values                 # shape: (number of datapoints, number of features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.33333333333333"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_proba, y_test_pred, test_accuracy = get_softmax_prediction(x_test, y_test, α, β, estimate_type='median')\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "bayes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
